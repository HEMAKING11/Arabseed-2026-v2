# arabseed_telegram_bot.py
import os
import re
import sys
import json
import time
import logging
import traceback
from urllib.parse import urlparse, unquote, urlunparse, quote
from typing import Dict, List, Optional, Tuple

import requests
from bs4 import BeautifulSoup
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    filters,
    ContextTypes,
    CallbackContext
)

# ----------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„ -----------------
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ----------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª -----------------
# Ø§Ø³ØªØ®Ø¯Ù… Ù…ØªØºÙŠØ± Ø¨ÙŠØ¦Ø© Ø£Ùˆ Ø¶Ø¹ Ø§Ù„ØªÙˆÙƒÙ† Ù‡Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©
TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "7064549403:AAHWQsrZPekW1M9kHacqB6N19aMj_xjspf4")

# ----------------- Ø§Ù„Ø£Ù„ÙˆØ§Ù† (Ù„Ù„Ø·Ø¨Ø§Ø¹Ø© ÙÙ‚Ø·) -----------------
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    RESET = '\033[0m'

# ----------------- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª -----------------
class UserSession:
    def __init__(self):
        self.processing = False
        self.auto_mode = False
        self.current_episode = 0
        self.builder_func = None
        self.last_url = ""
        self.last_title = ""
        
    def reset(self):
        self.processing = False
        self.auto_mode = False
        self.current_episode = 0
        self.builder_func = None

user_sessions = {}

def get_user_session(user_id: int) -> UserSession:
    if user_id not in user_sessions:
        user_sessions[user_id] = UserSession()
    return user_sessions[user_id]

# ----------------- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© (Ù…Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ) -----------------
def extract_base_url(url: str) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ"""
    parsed_url = urlparse(url)
    return f"{parsed_url.scheme}://{parsed_url.netloc}"

def extract_title_from_url(url: str) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
    parsed_url = urlparse(url)
    path = unquote(parsed_url.path)
    path_parts = path.strip('/').split('-')
    title = ' '.join(path_parts).replace('.html', '').title()
    if title.startswith("Ù…Ø³Ù„Ø³Ù„"):
        words = title.split()
        new_title = []
        for word in words:
            new_title.append(word)
            if any(char.isdigit() for char in word):
                break
        title = ' '.join(new_title)
    return title

def follow_redirect(url: str, session: Optional[requests.Session] = None, headers: Optional[Dict] = None, timeout: int = 10) -> Optional[str]:
    """ØªØªØ¨Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡"""
    if session is None:
        session = requests.Session()
    if headers is None:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}

    try:
        r = session.get(url, headers=headers, allow_redirects=False, timeout=timeout)
        if 'location' in r.headers:
            loc = r.headers['location']
            logger.info(f"Found location header: {loc}")
            return loc
        r2 = session.get(url, headers=headers, allow_redirects=True, timeout=timeout)
        final = r2.url
        logger.info(f"Final URL after redirects: {final}")
        return final
    except Exception as e:
        logger.error(f"Error following redirect: {e}")
        return None

def find_last_numeric_segment_in_path(path_unquoted: str) -> Tuple[Optional[int], Optional[str]]:
    """Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø£Ø®ÙŠØ± ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±"""
    parts = path_unquoted.strip('/').split('-')
    for i in range(len(parts)-1, -1, -1):
        if re.fullmatch(r'\d+', parts[i]):
            return i, parts[i]
    return None, None

def build_episode_url_from_any(url: str, episode_number: int) -> Optional[str]:
    """Ø¨Ù†Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ù„Ù‚Ø©"""
    p = urlparse(url)
    path_unquoted = unquote(p.path)
    idx, num = find_last_numeric_segment_in_path(path_unquoted)
    if idx is None:
        return None
    parts = path_unquoted.strip('/').split('-')[:idx+1]
    parts[-1] = str(episode_number)
    new_path = '/' + '-'.join(parts)
    quoted_path = quote(new_path, safe="/%")
    new_parsed = (p.scheme, p.netloc, quoted_path, '', '', '')
    return urlunparse(new_parsed)

def extract_episode_and_base(url: str) -> Tuple[Optional[int], Optional[callable]]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ø­Ù„Ù‚Ø© ÙˆØ¯Ø§Ù„Ø© Ø§Ù„Ø¨Ù†Ø§Ø¡"""
    p = urlparse(url)
    path_unquoted = unquote(p.path)
    idx, num = find_last_numeric_segment_in_path(path_unquoted)
    if idx is None or num is None:
        return None, None
    return int(num), lambda ep: build_episode_url_from_any(url, ep)

# ----------------- Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„ (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ) -----------------
def get_download_info(server_href: str, referer: str) -> Optional[Dict]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø±Ø§Ø¨Ø· Ø§Ù„Ø³ÙŠØ±ÙØ±"""
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Referer": referer
    })

    try:
        logger.info(f"Processing server link: {server_href}")
        
        # ØªØªØ¨Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡
        redirected = follow_redirect(server_href, session=session)
        if not redirected:
            logger.error(f"Couldn't obtain redirected r-link for {server_href}")
            return None

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ø§Ø¨Ø· ?r=
        r_link = None
        if '?r=' in redirected:
            r_link = redirected
        else:
            tmp = session.get(redirected, timeout=12)
            m = re.search(r'(https?://[^"\'>\s]+/category/downloadz/\?r=\d+[^"\'>\s]*)', tmp.text)
            if m:
                r_link = m.group(1)
            elif '?r=' in tmp.url:
                r_link = tmp.url
            else:
                if 'location' in tmp.headers and '?r=' in tmp.headers['location']:
                    r_link = tmp.headers['location']
        
        if not r_link:
            logger.error(f"Could not find ?r= link for {server_href}")
            return None

        logger.info(f"Found r_link: {r_link}")

        # ØªØ­Ù„ÙŠÙ„ ØµÙØ­Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
        rpage = session.get(r_link, timeout=12)
        rsoup = BeautifulSoup(rpage.text, 'html.parser')

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø²Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„
        btn_tag = rsoup.find('a', id='btn') or rsoup.select_one('a.downloadbtn') or rsoup.find('a', class_='downloadbtn')
        final_asd_url = None

        if btn_tag and btn_tag.get('href'):
            candidate = btn_tag.get('href')
            if candidate.startswith('/'):
                candidate = extract_base_url(r_link) + candidate
            final_asd_url = candidate
            logger.info(f"Found btn href: {final_asd_url}")
        else:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø§Ø¨Ø· Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹
            dynamic_param_pattern = r'([?&][a-zA-Z0-9_]+\d*=[^"&\']+)'
            qs_matches = re.findall(dynamic_param_pattern, rpage.text)
            params = []
            for q in qs_matches:
                normalized_param = q.lstrip('?&')
                if normalized_param.lower().startswith('r='):
                    continue
                param_name = normalized_param.split('=', 1)[0]
                if not any(p.startswith(param_name + '=') for p in params):
                    params.append(normalized_param)
            
            if params:
                sep = '&' if '?' in r_link else '?'
                final_asd_url = r_link + sep + '&'.join(params)
                logger.info(f"Constructed dynamic url: {final_asd_url}")

        if not final_asd_url:
            logger.warning("Falling back to r_link only")
            final_asd_url = r_link

        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        final_resp = session.get(final_asd_url, timeout=15)
        if final_resp.status_code != 200:
            logger.error(f"Failed loading final url (status {final_resp.status_code})")
            return None
            
        fsoup = BeautifulSoup(final_resp.text, 'html.parser')

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ø§Ø¨Ø· MP4 Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        final_tag = fsoup.find('a', id='btn') or fsoup.find('a', class_='downloadbtn') or fsoup.find('a', href=re.compile(r'\.mp4'))
        if not final_tag:
            logger.error("Couldn't locate final .mp4 link")
            return None

        file_link = final_tag.get('href')
        if file_link and file_link.startswith('/'):
            file_link = extract_base_url(final_asd_url) + file_link

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
        file_name = None
        file_size = None
        
        try:
            name_span = fsoup.select_one('.TitleCenteral h3 span')
            if name_span:
                file_name = name_span.get_text(strip=True)
            
            size_span = fsoup.select_one('.TitleCenteral h3:nth-of-type(2) span')
            if size_span:
                file_size = size_span.get_text(strip=True)
        except Exception:
            pass

        if not file_size:
            h3 = fsoup.find('h3')
            if h3:
                msize = re.search(r'Ø§Ù„Ø­Ø¬Ù…[:\s\-â€“]*([\d\.,]+\s*(?:MB|GB))', h3.get_text())
                if msize:
                    file_size = msize.group(1)

        if not file_name:
            file_name = os.path.basename(file_link) if file_link else "unknown"

        return {
            'direct_link': file_link.replace(" ", ".") if file_link else None,
            'file_name': file_name,
            'file_size': file_size or "Unknown"
        }

    except Exception as e:
        logger.error(f"Error extracting download info: {e}")
        return None

# ----------------- Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù„Ù‚Ø© (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ) -----------------
def process_single_episode(arabseed_url: str, session: requests.Session) -> Tuple[bool, Optional[str], Optional[List[List[Dict]]]]:
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ù„Ù‚Ø© ÙˆØ§Ø­Ø¯Ø©
    ØªØ±Ø¬Ø¹: (Ù†Ø¬Ø§Ø­/ÙØ´Ù„, Ø±Ø³Ø§Ù„Ø©/Ø¹Ù†ÙˆØ§Ù†, Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø²Ø±Ø§Ø±)
    """
    try:
        # ØªØªØ¨Ø¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø®ØªØµØ±Ø©
        if '/l/' in arabseed_url or 'reviewrate.net' in arabseed_url:
            arabseed_url = follow_redirect(arabseed_url, session=session) or arabseed_url

        # Ø¬Ù„Ø¨ ØµÙØ­Ø© Ø§Ù„Ø­Ù„Ù‚Ø©
        try:
            resp = session.get(arabseed_url, timeout=12)
        except Exception as e:
            logger.error(f"Connection error: {e}")
            return False, "âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„", None

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø­Ù„Ù‚Ø©
        if resp.status_code == 404:
            return False, "âŒ Ø§Ù„Ø­Ù„Ù‚Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© (404)", None
            
        if resp.status_code != 200:
            logger.warning(f"Status {resp.status_code} â€” retrying...")
            time.sleep(1.2)
            try:
                resp = session.get(arabseed_url, timeout=12)
            except Exception as e:
                logger.error(f"Retry connection error: {e}")
                return False, "âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©", None
                
            if resp.status_code != 200:
                return False, f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø­Ù„Ù‚Ø© (Ø±Ù…Ø²: {resp.status_code})", None

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø©
        text_lower = resp.text.lower()
        if any(phrase in text_lower for phrase in ['Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ±', 'page not found', 'ØµÙØ­Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©', 'not found']):
            return False, "âŒ Ø§Ù„Ø­Ù„Ù‚Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©", None

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ø§Ø¨Ø· ØµÙØ­Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
        soup = BeautifulSoup(resp.text, 'html.parser')
        download_anchor = soup.find('a', href=re.compile(r'/download/')) or soup.find('a', class_=re.compile(r'download__btn|downloadBTn'))
        
        if not download_anchor:
            return False, "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„", None

        # Ø¬Ù„Ø¨ ØµÙØ­Ø© Ø§Ù„Ø¬ÙˆØ¯Ø§Øª
        quality_page_url = download_anchor.get('href')
        if quality_page_url.startswith('/'):
            quality_page_url = extract_base_url(arabseed_url) + quality_page_url
        
        try:
            qresp = session.get(quality_page_url, headers={'Referer': extract_base_url(arabseed_url)}, timeout=12)
            if qresp.status_code != 200:
                return False, "âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ ØµÙØ­Ø© Ø§Ù„Ø¬ÙˆØ¯Ø§Øª", None
        except Exception as e:
            logger.error(f"Error loading quality page: {e}")
            return False, "âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ØµÙØ­Ø© Ø§Ù„Ø¬ÙˆØ¯Ø§Øª", None

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª
        qsoup = BeautifulSoup(qresp.text, 'html.parser')
        server_links = qsoup.find_all('a', href=re.compile(r'/l/'))
        if not server_links:
            server_links = qsoup.select('ul.downloads__links__list a') or qsoup.find_all('a', class_=re.compile(r'download__item|arabseed'))

        if not server_links:
            return False, "âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±ÙˆØ§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ù…ØªØ§Ø­Ø©", None

        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø³ÙŠØ±ÙØ±
        buttons_data = []
        referer = extract_base_url(quality_page_url) + "/"
        seen_qualities = set()

        for a in server_links:
            href = a.get('href')
            if not href:
                continue
                
            # ØªØ®Ø·ÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ØºÙŠØ± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
            if 'arabseed' not in href and 'Ø¹Ø±Ø¨ Ø³ÙŠØ¯' not in a.get_text(" ", strip=True):
                continue

            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬ÙˆØ¯Ø©
            quality = "Unknown"
            parent_with_quality = a.find_parent(attrs={"data-quality": True})
            if parent_with_quality:
                quality = parent_with_quality.get('data-quality')
            else:
                ptxt = a.get_text(" ", strip=True)
                qmatch = re.search(r'(\d{3,4}p)', ptxt)
                if qmatch:
                    quality = qmatch.group(1)
                else:
                    sq = a.find_previous('div', class_=re.compile(r'txt|text'))
                    if sq:
                        qmatch = re.search(r'(\d{3,4}p)', sq.get_text())
                        if qmatch:
                            quality = qmatch.group(1)

            if quality in seen_qualities:
                continue
            seen_qualities.add(quality)

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„
            logger.info(f"Processing server link ({quality}): {href}")
            info = get_download_info(href, referer)
            
            if info and info.get('direct_link'):
                btn_text = f"[ {info.get('file_size','?')} ]  â€¢  {quality}"
                buttons_data.append([{"text": btn_text, "url": info['direct_link']}])
                logger.info(f"Added Quality: {quality} ({info.get('file_size')})")

        if not buttons_data:
            return False, "âŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„", None

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
        media_title = extract_title_from_url(arabseed_url)
        return True, media_title, buttons_data

    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        return False, f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}", None

# ----------------- Ø¯ÙˆØ§Ù„ Telegram -----------------
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ø£Ù…Ø± /start"""
    user = update.effective_user
    welcome_text = f"""
ğŸ¬ *Ù…Ø±Ø­Ø¨Ø§Ù‹ {user.first_name}!*

ğŸ¤– *Ø¨ÙˆØª ØªØ­Ù…ÙŠÙ„ Ø¹Ø±Ø¨ Ø³ÙŠØ¯ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±*

ğŸ”— *ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:*
1. Ø£Ø±Ø³Ù„ Ø±Ø§Ø¨Ø· Ø­Ù„Ù‚Ø© Ù…Ù† Ù…ÙˆÙ‚Ø¹ Ø¹Ø±Ø¨ Ø³ÙŠØ¯
2. Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ØªØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø§Ø¨Ø·
3. Ø§Ø®ØªØ± Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ø£Ø²Ø±Ø§Ø±

ğŸ“Œ *Ù…Ø«Ø§Ù„ Ù„Ù„Ø±Ø§Ø¨Ø·:*
`https://arabseed.cam/Ù…Ø³Ù„Ø³Ù„-Ø§Ù„Ø¹Ù†ÙƒØ¨ÙˆØª-Ø§Ù„Ø­Ù„Ù‚Ø©-1.html`

ğŸ¯ *Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¨ÙˆØª:*
â€¢ ØªØ­Ù…ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø± Ø¨Ø¬ÙˆØ¯Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©
â€¢ Ø¯Ø¹Ù… Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø®ØªØµØ±Ø©
â€¢ ÙˆØ§Ø¬Ù‡Ø© Ø³Ù‡Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

âš¡ *ÙŠØ¹Ù…Ù„ 24/7 Ø¯ÙˆÙ† ØªÙˆÙ‚Ù*
    """
    
    keyboard = [
        [InlineKeyboardButton("ğŸ¬ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø§Ø¨Ø·", switch_inline_query_current_chat="")],
        [InlineKeyboardButton("ğŸ“¢ Ù‚Ù†Ø§Ø© Ø§Ù„Ø¯Ø¹Ù…", url="https://t.me/arabseed_support")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(welcome_text, reply_markup=reply_markup, parse_mode='Markdown')

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ø£Ù…Ø± /help"""
    help_text = """
ğŸ“– *ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙˆØª:*

1. ğŸ” Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ Ù…ÙˆÙ‚Ø¹ Ø¹Ø±Ø¨ Ø³ÙŠØ¯
2. ğŸ“‹ Ø§Ù†Ø³Ø® Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
3. ğŸ“© Ø£Ø±Ø³Ù„ Ø§Ù„Ø±Ø§Ø¨Ø· Ù‡Ù†Ø§ ÙÙŠ Ø§Ù„Ø¨ÙˆØª
4. â³ Ø§Ù†ØªØ¸Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø­ØªÙ‰ ØªØªÙ… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
5. ğŸ“¥ Ø§Ø®ØªØ± Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©

âš ï¸ *Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©:*
â€¢ Ø§Ù„Ø¨ÙˆØª Ù„Ø§ ÙŠØ®Ø²Ù† Ø£ÙŠ Ù…Ù„ÙØ§Øª Ø¹Ù„Ù‰ Ø³ÙŠØ±ÙØ±Ø§ØªÙ‡
â€¢ Ø§Ù„Ø¬ÙˆØ¯Ø© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø£ØµÙ„ÙŠ
â€¢ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù‚Ø¯ Ù„Ø§ ØªØ¹Ù…Ù„

ğŸ”„ *ÙÙŠ Ø­Ø§Ù„Ø© ÙˆØ¬ÙˆØ¯ Ù…Ø´ÙƒÙ„Ø©:*
â€¢ ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø±Ø§Ø¨Ø·
â€¢ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø¹Ø¯ Ù‚Ù„ÙŠÙ„
â€¢ ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¯Ø¹Ù… Ø¹Ø¨Ø± @arabseed_support
    """
    
    await update.message.reply_text(help_text, parse_mode='Markdown')

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„"""
    user_id = update.effective_user.id
    session = get_user_session(user_id)
    
    if session.processing:
        await update.message.reply_text("â³ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ Ø§Ù„Ø³Ø§Ø¨Ù‚ØŒ Ø§Ù†ØªØ¸Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹...")
        return
    
    session.processing = True
    url = update.message.text.strip()
    
    try:
        # Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
        wait_msg = await update.message.reply_text("â³ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø§Ø¨Ø·ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø·Ù„Ø¨Ø§Øª
        req_session = requests.Session()
        req_session.headers.update({"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"})
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø§Ø¨Ø·
        success, title_or_msg, buttons_data = process_single_episode(url, req_session)
        
        if success:
            # Ø­Ø°Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
            await wait_msg.delete()
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø£Ø²Ø±Ø§Ø± Telegram
            keyboard = []
            for button_row in buttons_data:
                row = []
                for button in button_row:
                    row.append(InlineKeyboardButton(button["text"], url=button["url"]))
                keyboard.append(row)
            
            # Ø¥Ø¶Ø§ÙØ© Ø£Ø²Ø±Ø§Ø± Ø¥Ø¶Ø§ÙÙŠØ©
            keyboard.append([
                InlineKeyboardButton("ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø§Ø¨Ø· Ø¢Ø®Ø±", callback_data="new_link"),
                InlineKeyboardButton("ğŸ“¢ Ù‚Ù†Ø§Ø© Ø§Ù„Ø¯Ø¹Ù…", url="https://t.me/arabseed_support")
            ])
            
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø¹ Ø§Ù„Ø£Ø²Ø±Ø§Ø±
            message_text = f"""
ğŸ¬ *{title_or_msg}*

ğŸ“¥ *Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­Ø©:*
Ø§Ø®ØªØ± Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù…Ù† Ø§Ù„Ø£Ø²Ø±Ø§Ø± Ø£Ø¯Ù†Ø§Ù‡.

ğŸ”” *Ù…Ù„Ø§Ø­Ø¸Ø©:* Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø³ÙŠØ±ÙØ±Ø§Øª Ø¹Ø±Ø¨ Ø³ÙŠØ¯
            """
            
            await update.message.reply_text(
                message_text,
                reply_markup=reply_markup,
                parse_mode='Markdown'
            )
            
            # Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
            session.last_url = url
            session.last_title = title_or_msg
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø±Ø§Ø¨Ø· Ù…Ø³Ù„Ø³Ù„
            if 'Ù…Ø³Ù„Ø³Ù„' in unquote(urlparse(url).path) or 'Ø§Ù„Ø­Ù„Ù‚Ø©' in unquote(urlparse(url).path):
                current_num, builder = extract_episode_and_base(url)
                if current_num is not None and builder is not None:
                    session.current_episode = current_num + 1  # Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
                    session.builder_func = builder
                    
                    # Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù† ÙˆØ¶Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
                    auto_keyboard = [
                        [
                            InlineKeyboardButton("âœ… Ù†Ø¹Ù…", callback_data="auto_yes"),
                            InlineKeyboardButton("âŒ Ù„Ø§", callback_data="auto_no")
                        ]
                    ]
                    auto_markup = InlineKeyboardMarkup(auto_keyboard)
                    
                    await update.message.reply_text(
                        f"ğŸ¯ *ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù…Ø³Ù„Ø³Ù„*\n\nÙ‡Ù„ ØªØ±ÙŠØ¯ ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ØŸ",
                        reply_markup=auto_markup,
                        parse_mode='Markdown'
                    )
        
        else:
            await wait_msg.delete()
            await update.message.reply_text(f"{title_or_msg}\n\nâš ï¸ ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø±Ø§Ø¨Ø· ÙˆØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
            
    except Exception as e:
        logger.error(f"Error in handle_message: {e}\n{traceback.format_exc()}")
        await update.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
        
    finally:
        session.processing = False

async def handle_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¶ØºØ·Ø§Øª Ø§Ù„Ø£Ø²Ø±Ø§Ø±"""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    session = get_user_session(user_id)
    
    if query.data == "new_link":
        await query.edit_message_text("ğŸ”„ Ø£Ø±Ø³Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©...")
        
    elif query.data == "auto_yes":
        session.auto_mode = True
        await query.edit_message_text("âœ… *ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ*\n\nØ¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹...", parse_mode='Markdown')
        
        # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        await auto_process_episodes(update, context, user_id)
        
    elif query.data == "auto_no":
        session.auto_mode = False
        await query.edit_message_text("âŒ *ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ*\n\nÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø§Ø¨Ø· Ø¬Ø¯ÙŠØ¯ Ø¹Ù†Ø¯Ù…Ø§ ØªØ±ÙŠØ¯.", parse_mode='Markdown')

async def auto_process_episodes(update: Update, context: ContextTypes.DEFAULT_TYPE, user_id: int):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù„Ù‚Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
    session = get_user_session(user_id)
    
    if not session.auto_mode:
        return
    
    max_episodes = 10  # Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ Ø­Ù„Ù‚Ø§Øª Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø²Ø§Ø¦Ø¯
    
    for i in range(max_episodes):
        if not session.auto_mode:
            break
            
        if session.builder_func is None:
            break
            
        episode_url = session.builder_func(session.current_episode)
        if not episode_url:
            break
        
        try:
            # Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ØªØªØ¨Ø¹
            status_msg = await context.bot.send_message(
                chat_id=user_id,
                text=f"â³ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù„Ù‚Ø© {session.current_episode}..."
            )
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù„Ù‚Ø©
            req_session = requests.Session()
            req_session.headers.update({"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"})
            
            success, title_or_msg, buttons_data = process_single_episode(episode_url, req_session)
            
            if success:
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø£Ø²Ø±Ø§Ø±
                keyboard = []
                for button_row in buttons_data:
                    row = []
                    for button in button_row:
                        row.append(InlineKeyboardButton(button["text"], url=button["url"]))
                    keyboard.append(row)
                
                keyboard.append([
                    InlineKeyboardButton("â¹ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ", callback_data="stop_auto")
                ])
                
                reply_markup = InlineKeyboardMarkup(keyboard)
                
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                await context.bot.send_message(
                    chat_id=user_id,
                    text=f"ğŸ¬ *Ø§Ù„Ø­Ù„Ù‚Ø© {session.current_episode} - {title_or_msg}*\n\nğŸ“¥ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„:",
                    reply_markup=reply_markup,
                    parse_mode='Markdown'
                )
                
                # Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
                session.current_episode += 1
                
                # ØªØ£Ø®ÙŠØ± Ù‚ØµÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø­Ù„Ù‚Ø§Øª
                await asyncio.sleep(2)
                
            else:
                # Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ø­Ù„Ù‚Ø©ØŒ ØªÙˆÙ‚Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
                await context.bot.send_message(
                    chat_id=user_id,
                    text=f"âš ï¸ *ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ*\n\n{title_or_msg}",
                    parse_mode='Markdown'
                )
                session.auto_mode = False
                break
                
            # Ø­Ø°Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØªØ¨Ø¹
            await status_msg.delete()
            
        except Exception as e:
            logger.error(f"Error in auto processing: {e}")
            await context.bot.send_message(
                chat_id=user_id,
                text=f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù„Ù‚Ø© {session.current_episode}"
            )
            session.auto_mode = False
            break

async def stop_auto_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
    user_id = update.effective_user.id
    session = get_user_session(user_id)
    session.auto_mode = False
    await update.message.reply_text("â¹ *ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ*", parse_mode='Markdown')

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
    logger.error(f"Update {update} caused error {context.error}")
    
    if update and update.effective_message:
        try:
            await update.effective_message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
        except:
            pass

# ----------------- Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ -----------------
def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print(f"{Colors.GREEN}ğŸ¬ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø¨ÙˆØª Ø¹Ø±Ø¨ Ø³ÙŠØ¯ Telegram...{Colors.RESET}")
    print(f"{Colors.CYAN}Token: {TOKEN[:10]}...{Colors.RESET}")
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
        application = Application.builder().token(TOKEN).build()
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª
        application.add_handler(CommandHandler("start", start_command))
        application.add_handler(CommandHandler("help", help_command))
        application.add_handler(CommandHandler("stop", stop_auto_command))
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        application.add_handler(CallbackQueryHandler(handle_callback))
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        application.add_error_handler(error_handler)
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ø¨ÙˆØª
        print(f"{Colors.GREEN}ğŸ¤– Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†!{Colors.RESET}")
        print(f"{Colors.YELLOW}Ø§Ø¶ØºØ· Ctrl+C Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨ÙˆØª{Colors.RESET}")
        
        application.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)
        
    except Exception as e:
        logger.error(f"Failed to start bot: {e}")
        print(f"{Colors.RED}âŒ ÙØ´Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª: {e}{Colors.RESET}")

if __name__ == "__main__":
    # Ø¥Ø¶Ø§ÙØ© asyncio Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
    import asyncio
    main()